// Servi√ßo de Integra√ß√£o com Large Language Models
import { NLPResult } from '../nlp/NLPService';

export interface LLMResponse {
  response: string;
  confidence: number;
  suggestedActions?: string[];
  followUpQuestions?: string[];
  resources?: string[];
}

export interface ConversationContext {
  userProfile: {
    ageGroup: '60+' | 'senior' | 'adult';
    techExperience: 'beginner' | 'intermediate' | 'advanced';
    preferredStyle: 'detailed' | 'concise' | 'step-by-step';
    accessibilityNeeds: string[];
  };
  currentTopic: string;
  recentTopics: string[];
  userFrustrationLevel: number;
  sessionMessages: number;
}

export class LLMService {
  private apiKey: string | null = null;
  private baseURL = 'https://api.openai.com/v1';
  
  // Prompts especializados para Sofia
  private systemPrompts = {
    main: `Voc√™ √© Sofia, uma assistente digital especializada em ajudar pessoas com 60+ anos, PCDs e iniciantes em tecnologia. 

PERSONALIDADE:
- Extremamente paciente e carinhosa
- Usa linguagem simples, sem jarg√µes t√©cnicos
- Sempre explica passo a passo
- Oferece encorajamento constante
- Adapta explica√ß√µes ao n√≠vel do usu√°rio

DIRETRIZES:
- Use analogias do cotidiano para explicar conceitos t√©cnicos
- Divida tarefas complexas em etapas pequenas
- Sempre pergunte se o usu√°rio conseguiu seguir
- Ofere√ßa alternativas quando algo n√£o funciona
- Seja espec√≠fica sobre onde tocar/clicar
- Use emojis para tornar a conversa mais amig√°vel
- Evite termos como "clique", prefira "toque" ou "aperte"
- Sempre valide os sentimentos do usu√°rio

FORMATO DE RESPOSTA:
- Comece com empatia/valida√ß√£o
- Explique o conceito de forma simples
- D√™ instru√ß√µes passo a passo numeradas
- Termine com encorajamento
- Ofere√ßa ajuda adicional`,

    frustrated: `O usu√°rio est√° demonstrando frustra√ß√£o. Seja especialmente paciente e emp√°tica. 
Comece validando os sentimentos, simplifique ainda mais as explica√ß√µes e divida em passos menores.
Use frases como "Entendo sua frustra√ß√£o, isso √© normal" e "Vamos devagar, sem pressa".`,

    beginner: `O usu√°rio √© iniciante. Use linguagem extremamente simples, explique cada termo t√©cnico,
use analogias familiares e seja muito detalhada nas instru√ß√µes. Sempre explique "por que" al√©m do "como".`,

    followUp: `Esta √© uma pergunta de seguimento. Referencie a conversa anterior e construa sobre o que
j√° foi ensinado. Conecte com conceitos j√° explicados.`
  };

  constructor() {
    // API key ser√° configurada via ambiente ou configura√ß√µes do usu√°rio
    this.apiKey = null;
  }

  async generateResponse(
    userMessage: string,
    nlpResult: NLPResult,
    context: ConversationContext,
    conversationHistory: Array<{ text: string; isBot: boolean }>
  ): Promise<LLMResponse> {
    
    // Se n√£o h√° API key, usar fallback local
    if (!this.apiKey) {
      return this.generateLocalResponse(userMessage, nlpResult, context);
    }

    try {
      const prompt = this.buildPrompt(userMessage, nlpResult, context, conversationHistory);
      
      const response = await fetch(`${this.baseURL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini', // Modelo mais eficiente para este uso
          messages: [
            { role: 'system', content: this.getSystemPrompt(nlpResult, context) },
            { role: 'user', content: prompt }
          ],
          max_tokens: 500,
          temperature: 0.7,
          presence_penalty: 0.6,
          frequency_penalty: 0.3
        })
      });

      if (!response.ok) {
        throw new Error(`API Error: ${response.status}`);
      }

      const data = await response.json();
      const llmResponse = data.choices[0].message.content;

      return this.processLLMResponse(llmResponse, nlpResult);

    } catch (error) {
      console.error('LLM API Error:', error);
      // Fallback para resposta local
      return this.generateLocalResponse(userMessage, nlpResult, context);
    }
  }

  private buildPrompt(
    userMessage: string,
    nlpResult: NLPResult,
    context: ConversationContext,
    history: Array<{ text: string; isBot: boolean }>
  ): string {
    let prompt = `MENSAGEM DO USU√ÅRIO: "${userMessage}"\n\n`;

    // Adicionar an√°lise NLP
    prompt += `AN√ÅLISE DA MENSAGEM:
- Inten√ß√£o: ${nlpResult.intent} (confian√ßa: ${nlpResult.confidence})
- Sentimento: ${nlpResult.sentiment.label} (${nlpResult.sentiment.confidence})
- T√≥pico: ${nlpResult.topic}
- Urg√™ncia: ${nlpResult.urgency}
- N√≠vel: ${nlpResult.difficulty}
- Entidades: ${nlpResult.entities.map(e => `${e.type}:${e.value}`).join(', ')}\n\n`;

    // Adicionar contexto do usu√°rio
    prompt += `PERFIL DO USU√ÅRIO:
- Experi√™ncia: ${context.userProfile.techExperience}
- Estilo preferido: ${context.userProfile.preferredStyle}
- N√≠vel de frustra√ß√£o: ${context.userFrustrationLevel}/1.0
- T√≥pico atual: ${context.currentTopic}
- Necessidades de acessibilidade: ${context.userProfile.accessibilityNeeds.join(', ')}\n\n`;

    // Adicionar hist√≥rico recente se relevante
    if (history.length > 2) {
      const recentHistory = history.slice(-4).map(msg => 
        `${msg.isBot ? 'Sofia' : 'Usu√°rio'}: ${msg.text.substring(0, 100)}...`
      ).join('\n');
      prompt += `CONVERSA RECENTE:\n${recentHistory}\n\n`;
    }

    prompt += `Responda como Sofia, seguindo todas as diretrizes do sistema. A resposta deve ser personalizada para este usu√°rio espec√≠fico.`;

    return prompt;
  }

  private getSystemPrompt(nlpResult: NLPResult, context: ConversationContext): string {
    let systemPrompt = this.systemPrompts.main;

    // Adaptar prompt baseado na an√°lise
    if (nlpResult.sentiment.label === 'frustrated' || context.userFrustrationLevel > 0.5) {
      systemPrompt += '\n\n' + this.systemPrompts.frustrated;
    }

    if (nlpResult.difficulty === 'beginner' || context.userProfile.techExperience === 'beginner') {
      systemPrompt += '\n\n' + this.systemPrompts.beginner;
    }

    if (context.sessionMessages > 3) {
      systemPrompt += '\n\n' + this.systemPrompts.followUp;
    }

    return systemPrompt;
  }

  private processLLMResponse(llmResponse: string, nlpResult: NLPResult): LLMResponse {
    // Extrair a√ß√µes sugeridas (procurar por listas numeradas ou com bullet points)
    const actionPattern = /(?:^\d+\.|^[-‚Ä¢])\s*(.+)$/gm;
    const suggestedActions: string[] = [];
    let match;
    while ((match = actionPattern.exec(llmResponse)) !== null) {
      suggestedActions.push(match[1].trim());
    }

    // Extrair perguntas de follow-up
    const questionPattern = /\?[^?]*$/gm;
    const followUpQuestions: string[] = [];
    const questions = llmResponse.match(questionPattern);
    if (questions) {
      followUpQuestions.push(...questions.map(q => q.trim()));
    }

    // Gerar recursos baseados no t√≥pico
    const resources = this.generateResources(nlpResult.topic, nlpResult.intent);

    return {
      response: llmResponse,
      confidence: 0.8, // Alta confian√ßa para LLM
      suggestedActions: suggestedActions.slice(0, 3), // M√°ximo 3 a√ß√µes
      followUpQuestions: followUpQuestions.slice(0, 2), // M√°ximo 2 perguntas
      resources
    };
  }

  private generateLocalResponse(
    userMessage: string,
    nlpResult: NLPResult,
    context: ConversationContext
  ): LLMResponse {
    // Sistema de fallback com respostas estruturadas
    const templates = this.getResponseTemplates();
    const template = templates[nlpResult.intent] || templates.default;

    let response = this.personalizeTemplate(template, nlpResult, context);
    
    // Adaptar para sentimento
    if (nlpResult.sentiment.label === 'frustrated') {
      response = `Entendo sua frustra√ß√£o, isso √© muito comum! üòä ${response}\n\nLembre-se: n√£o h√° pressa, vamos devagar e voc√™ vai conseguir! üíô`;
    } else if (nlpResult.sentiment.label === 'confused') {
      response = `Sei que pode parecer confuso no in√≠cio, mas vou explicar de forma bem simples! üòä\n\n${response}`;
    }

    return {
      response,
      confidence: 0.6,
      suggestedActions: this.generateSuggestedActions(nlpResult.intent),
      followUpQuestions: this.generateFollowUpQuestions(nlpResult.intent),
      resources: this.generateResources(nlpResult.topic, nlpResult.intent)
    };
  }

  private getResponseTemplates(): { [key: string]: string } {
    return {
      whatsapp: `Vou te ajudar com o WhatsApp! üì±

**Passo a passo para ${this.extractAction()} no WhatsApp:**

1. **Encontre o aplicativo**: Procure o √≠cone verde com um telefone branco na tela do seu celular
2. **Abra o WhatsApp**: Toque uma vez no √≠cone verde
3. **Aguarde carregar**: O aplicativo vai abrir (pode demorar alguns segundos)

Se voc√™ n√£o encontrar o aplicativo, me avise que te ajudo a localiz√°-lo! üòä`,

      email: `Vou te explicar como usar o e-mail de forma simples! üìß

**Para ${this.extractAction()} e-mail:**

1. **Encontre o aplicativo de e-mail**: Procure um √≠cone que parece um envelope
2. **Abra o aplicativo**: Toque no √≠cone
3. **Aguarde carregar**: Suas mensagens v√£o aparecer

Qual parte voc√™ gostaria que eu explique com mais detalhes?`,

      default: `Entendo sua pergunta! Vou te ajudar de forma bem simples e passo a passo. üòä

Me conte um pouco mais sobre o que voc√™ est√° tentando fazer, assim posso dar explica√ß√µes mais espec√≠ficas para voc√™.

Lembre-se: n√£o existe pergunta boba, e estou aqui para te ajudar com toda paci√™ncia do mundo! üíô`
    };
  }

  private extractAction(): string {
    // M√©todo auxiliar para extrair a√ß√£o da mensagem
    return "usar"; // Simplificado
  }

  private personalizeTemplate(
    template: string,
    nlpResult: NLPResult,
    context: ConversationContext
  ): string {
    // Personalizar template baseado no contexto
    let personalized = template;

    // Adaptar para n√≠vel de experi√™ncia
    if (context.userProfile.techExperience === 'beginner') {
      personalized = personalized.replace(/toque/g, 'aperte com o dedo');
      personalized = personalized.replace(/aplicativo/g, 'programa do celular');
    }

    return personalized;
  }

  private generateSuggestedActions(intent: string): string[] {
    const actions: { [key: string]: string[] } = {
      whatsapp: [
        "Vamos localizar o WhatsApp no seu celular",
        "Te ensino a enviar sua primeira mensagem", 
        "Explico como enviar fotos pelo WhatsApp"
      ],
      email: [
        "Vamos configurar seu e-mail",
        "Te ensino a enviar um e-mail",
        "Explico como ler mensagens recebidas"
      ],
      default: [
        "Me conte mais detalhes sobre sua d√∫vida",
        "Vamos come√ßar pelo b√°sico",
        "Posso explicar de outra forma"
      ]
    };

    return actions[intent] || actions.default;
  }

  private generateFollowUpQuestions(intent: string): string[] {
    const questions: { [key: string]: string[] } = {
      whatsapp: [
        "Voc√™ consegue ver o √≠cone do WhatsApp na tela?",
        "J√° usou WhatsApp antes ou √© a primeira vez?"
      ],
      email: [
        "Voc√™ j√° tem uma conta de e-mail configurada?",
        "Qual aplicativo de e-mail voc√™ est√° usando?"
      ],
      default: [
        "Voc√™ conseguiu seguir at√© aqui?",
        "Tem alguma parte que ficou confusa?"
      ]
    };

    return questions[intent] || questions.default;
  }

  private generateResources(topic: string, intent: string): string[] {
    const resourceMap: { [key: string]: string[] } = {
      'Comunica√ß√£o': [
        "Tutorial b√°sico de WhatsApp",
        "Como fazer liga√ß√µes",
        "Enviar mensagens de texto"
      ],
      'M√≠dia e Fotos': [
        "Como tirar fotos",
        "Enviar fotos pelo WhatsApp",
        "Organizar galeria de fotos"
      ],
      'Conectividade': [
        "Como conectar WiFi",
        "Resolver problemas de internet",
        "Usar dados m√≥veis"
      ]
    };

    return resourceMap[topic] || ["Ajuda b√°sica com celular", "Suporte t√©cnico"];
  }

  // M√©todo para configurar API key
  setApiKey(apiKey: string) {
    this.apiKey = apiKey;
  }

  // M√©todo para verificar se LLM est√° dispon√≠vel
  isLLMAvailable(): boolean {
    return this.apiKey !== null;
  }
}